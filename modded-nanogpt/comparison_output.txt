logs/ef45ca64-a773-481b-b72a-b8ec5d49f0e6.txt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/grace/Projects/nGPT-muon/modded-nanogpt/train_baseline_production.py", line 1694, in <module>
[rank0]:     (model(inputs, targets, cum_seqlens, ws_long//2, ws_long, mtp_weights) / grad_accum_steps).backward()
[rank0]:      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1780, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1791, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/grace/Projects/nGPT-muon/modded-nanogpt/train_baseline_production.py", line 1223, in forward
[rank0]:     x = self.blocks[i](x, attn_args)
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1780, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1791, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/grace/Projects/nGPT-muon/modded-nanogpt/train_baseline_production.py", line 1084, in forward
[rank0]:     attn_out = self.attn(x, attn_args)  # NO norm() wrapper
[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1780, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1791, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/grace/Projects/nGPT-muon/modded-nanogpt/train_baseline_production.py", line 1022, in forward
[rank0]:     q, k = rotary(q, cos, sin), rotary(k, cos, sin)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/grace/Projects/nGPT-muon/modded-nanogpt/train_baseline_production.py", line 930, in rotary
[rank0]:     assert cos.size(0) >= x_BTHD.size(-3)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: AssertionError
[rank0]:[W1225 20:55:11.793166266 ProcessGroupNCCL.cpp:1558] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
E1225 20:55:12.461000 47674 torch/distributed/elastic/multiprocessing/api.py:984] failed (exitcode: 1) local_rank: 0 (pid: 47748) of binary: /home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/bin/python3
Traceback (most recent call last):
  File "/home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/bin/torchrun", line 10, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 362, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/lib/python3.12/site-packages/torch/distributed/run.py", line 992, in main
    run(args)
  File "/home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/lib/python3.12/site-packages/torch/distributed/run.py", line 983, in run
    elastic_launch(
  File "/home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 170, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/grace/Projects/nGPT-muon/modded-nanogpt/.venv/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 317, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_baseline_production.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-12-25_20:55:12
  host      : gracehopper
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 47748)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================

================================================================================
PRODUCTION COMPARISON: modded-nanogpt vs Optimized Gated nGPT
================================================================================
Dataset: FineWeb10B (2 shards)
Steps: 400
Model: 11 layers × 768 dim (155M parameters)
================================================================================

Cleared previous results

================================================================================
EXPERIMENT 1: Production Baseline (modded-nanogpt)
================================================================================
Configuration:
  - Architecture: Standard GPT 11×768 (155M params)
  - Optimizers: Muon (lr=0.023) + DistAdam (lr=0.008)
  - FP8 quantization: Enabled
  - Batch size: 32 (constant)
  - Training: 2 shards, 400 steps
--------------------------------------------------------------------------------

✗ Baseline failed with return code 1
Baseline failed, aborting comparison
